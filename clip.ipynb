{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ftfy regex tqdm\n",
    "# !pip install git+https://github.com/openai/CLIP.git\n",
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "from PIL import Image\n",
    "from urllib import request\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data = pd.read_table(\"./data/photos.tsv000\")\n",
    "id_data = id_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['morning','noon','afternoon','night','sunrise or sunset']\n",
    "tkns = ['A photo taken at '+label for label in labels]\n",
    "text = clip.tokenize(tkns).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "ln = len(id_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:11<00:00,  1.12s/it]███████████| 10/10 [00:11<00:00,  1.00s/it]\n",
      "100%|█████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "import tqdm.asyncio as tqdm\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "\n",
    "async def process_url(img, name):\n",
    "\n",
    "    resp = requests.get(img, stream = True)\n",
    "    if resp.status_code == 200:\n",
    "        with open(f'/home/gk/vscode/mentos2/imgs/{name}.jpg', mode='wb') as f:\n",
    "                f.write(resp.content)\n",
    "    \n",
    "\n",
    "async def main(id_data):\n",
    "    \n",
    "    pbar = tqdm.tqdm(total=ln, position=0, ncols=90)\n",
    "    for img, name in tqdm.tqdm(id_data[['photo_image_url','photo_id']].values):\n",
    "        await asyncio.gather(process_url(img, name))\n",
    "        pbar.update()\n",
    "    \n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "await main(id_data[:10])\n",
    "exec_time = (datetime.datetime.now() - start).seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:07<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(0,ln,BATCH_SIZE)):\n",
    "    images = [\n",
    "        preprocess(\n",
    "            Image.open(f\"/home/gk/vscode/mentos2/imgs/{img_id}.jpg\")\n",
    "        ) for img_id in id_data['photo_id'][i:i+BATCH_SIZE]\n",
    "    ]\n",
    "    \n",
    "    image_input = torch.tensor(np.stack(images)).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "\n",
    "        logits_per_image, logits_per_text = model(image_input, text)\n",
    "\n",
    "        # The softmax function takes the original confidence \n",
    "        # and applys a transform to make all the confidence add up to one\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "        results.append(probs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.24939512, 0.11317686, 0.5617848 , 0.04105058, 0.03459259],\n",
       "        [0.42064378, 0.22109112, 0.3413293 , 0.00406866, 0.01286716]],\n",
       "       dtype=float32),\n",
       " array([[0.3431934 , 0.4437798 , 0.16850986, 0.00502489, 0.03949203],\n",
       "        [0.46548992, 0.10493674, 0.36747718, 0.00647406, 0.055622  ]],\n",
       "       dtype=float32),\n",
       " array([[0.3381277 , 0.13543364, 0.49400395, 0.01339193, 0.01904278],\n",
       "        [0.38754764, 0.09125071, 0.3338901 , 0.00306765, 0.18424398]],\n",
       "       dtype=float32),\n",
       " array([[4.2146990e-01, 4.6916127e-02, 2.1870366e-01, 6.8997761e-04,\n",
       "         3.1222031e-01],\n",
       "        [9.2957430e-02, 1.4701550e-02, 3.8343336e-02, 1.4332941e-02,\n",
       "         8.3966470e-01]], dtype=float32),\n",
       " array([[0.37139437, 0.00996081, 0.04555314, 0.00794072, 0.565151  ],\n",
       "        [0.31442267, 0.23331885, 0.2961083 , 0.02424738, 0.13190274]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.concatenate(results,axis=0)\n",
    "choices = np.argmax(res,axis=1)\n",
    "choices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38328/1349465846.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  id_data['time'] = times\n"
     ]
    }
   ],
   "source": [
    "getlabel = lambda x:labels[x]\n",
    "vgetlabel = np.vectorize(getlabel)\n",
    "times = vgetlabel(choices)\n",
    "id_data['time'] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "morning              5\n",
       "afternoon            2\n",
       "sunrise or sunset    2\n",
       "noon                 1\n",
       "Name: time, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_data['time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0ae4fa97a57fd8d950a2fae74bbb6f77555dfa0963c93066e74e2214e6bf19f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
